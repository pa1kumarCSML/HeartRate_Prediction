{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c06f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d77a650c-607e-43e7-bd90-b879971eec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.signal import butter, filtfilt, lfilter\n",
    "from scipy.fft import fft, fftfreq\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20066f42-c946-4958-ba84-65c83a6285d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "low_cutoff = 0.75\n",
    "high_cutoff = 2.5\n",
    "fps=0\n",
    "fs = 2 * high_cutoff\n",
    "\n",
    "#Paths\n",
    "dlib_path = 'dlib_files/shape_predictor_68_face_landmarks.dat'\n",
    "video_path = ''\n",
    "\n",
    "# Load face detector and facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(dlib_path)\n",
    "\n",
    "#pulses values\n",
    "pulses_forehead=[]\n",
    "pulses_leftc=[]\n",
    "pulses_rightc=[]\n",
    "# pulses_fullf=[]\n",
    "\n",
    "# Create a new DataFrame with new columns data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "95128bd6-f4c6-4990-869a-3ad47265d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(folder_path)\n",
    "    print(folder_path)\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d0689a4b-430b-4a4f-88e0-44b82a06b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "\n",
    "def setValues():\n",
    "    #Constants\n",
    "    low_cutoff = 0.75\n",
    "    high_cutoff = 2.5\n",
    "    fs = 2 * high_cutoff    \n",
    "    #pulses values\n",
    "    pulses_forehead=[]\n",
    "    pulses_leftc=[]\n",
    "    pulses_rightc=[]\n",
    "    # pulses_fullf=[]\n",
    "\n",
    "\n",
    "def calculate_pulse_signal(roi,pulses):\n",
    "    \n",
    "    B, G, R = cv2.split(roi)\n",
    "    \n",
    "    #Normalizing R,G,B channels\n",
    "    \n",
    "    Rn = R / np.mean(R)\n",
    "    Gn = G / np.mean(G)\n",
    "    Bn = B / np.mean(B)    \n",
    "    \n",
    "    #CHROM Signals\n",
    "    \n",
    "    Xs = 3*Rn - 2*Gn\n",
    "    Ys = 1.5*Rn + Gn - 1.5*Bn\n",
    "    \n",
    "    Rf = apply_bandpass_filter(Rn)\n",
    "    Gf = apply_bandpass_filter(Gn)\n",
    "    Bf = apply_bandpass_filter(Bn)\n",
    "    Xf = apply_bandpass_filter(Xs)\n",
    "    Yf = apply_bandpass_filter(Ys)\n",
    "\n",
    "    alpha = np.std(Xf) / np.std(Yf)\n",
    "\n",
    "    Signal = 3*(1-(alpha/2))*Rf - 2*(1 + (alpha/2))*Gf + ((3*alpha)/2)*Bf\n",
    "    \n",
    "    pulses.append(np.mean(Signal))  \n",
    "\n",
    "def apply_bandpass_filter(channel, order=5):\n",
    "    b, a = butter_bandpass(order)\n",
    "    y = filtfilt(b, a, channel, axis=0,padlen=0)\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(order=5):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    lowcut_norm = low_cutoff / nyquist \n",
    "    highcut_norm = high_cutoff / nyquist\n",
    "    b, a = butter(order, [lowcut_norm, highcut_norm-0.1], btype='band')\n",
    "    return b, a\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2dd5d9fc-c94d-444f-bfe0-08db04b0115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "\n",
    "def calculateResult(file_path):\n",
    "    print(file_path)\n",
    "    data = {\n",
    "    'fl': np.nan,\n",
    "    'fr': np.nan,\n",
    "    'rl': np.nan,\n",
    "    'facecount': np.nan,\n",
    "    'error':0\n",
    "    }\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    setValues()\n",
    "    \n",
    "    # Process each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # handle if not ret\n",
    "            data['error'] = 1\n",
    "            print(ret)\n",
    "            return data\n",
    "            break\n",
    "    \n",
    "        # Convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Detect faces in the frame\n",
    "        faces = detector(gray)\n",
    "        \n",
    "        if(len(faces) > 1):\n",
    "            data['facecount'] = len(faces)\n",
    "            return data\n",
    "            break\n",
    "    \n",
    "        # Process each detected face\n",
    "        for face in faces:\n",
    "            # Detect facial landmarks\n",
    "            landmarks = predictor(gray, face)\n",
    "            \n",
    "            # Identify forehead region based on landmarks\n",
    "            forehead_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            forehead_r1[0] = landmarks.part(21).x # Left eyebrow-x\n",
    "            forehead_r1[1] = landmarks.part(22).x  # Right eyebrow-x\n",
    "            forehead_r1_height=int((forehead_r1[1] - forehead_r1[0]))\n",
    "            forehead_r1[2] = landmarks.part(21).y - forehead_r1_height # Left eyebrow-y\n",
    "            forehead_r1[3] = landmarks.part(22).y # Right eyebrow-y\n",
    "            \n",
    "            # Identify left cheek region-1 based on landmarks\n",
    "            leftc_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            leftc_r1[0]=landmarks.part(41).x\n",
    "            leftc_r1[1]=landmarks.part(39).x\n",
    "            leftc_r1[2]=landmarks.part(28).y\n",
    "            leftc_r1[3]=landmarks.part(30).y\n",
    "    \n",
    "            # Identify right cheek region-1 based on landmarks\n",
    "            rightc_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            rightc_r1[0]=landmarks.part(42).x\n",
    "            rightc_r1[1]=landmarks.part(46).x\n",
    "            rightc_r1[2]=landmarks.part(28).y\n",
    "            rightc_r1[3]=landmarks.part(30).y\n",
    "            \n",
    "            try:\n",
    "                calculate_pulse_signal(frame[forehead_r1[2]:forehead_r1[3],forehead_r1[0]:forehead_r1[1]],pulses_forehead)\n",
    "                calculate_pulse_signal(frame[leftc_r1[2]:leftc_r1[3],leftc_r1[0]:leftc_r1[1]],pulses_leftc)\n",
    "                calculate_pulse_signal(frame[rightc_r1[2]:rightc_r1[3],rightc_r1[0]:rightc_r1[1]],pulses_rightc)   \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                data['error']=1\n",
    "                return data\n",
    "    \n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            # handle if q pressed\n",
    "            break\n",
    "    # Release video capture\n",
    "    cap.release()\n",
    "\n",
    "    # data = {'full_face': pulses_fullf, 'forehead': pulses_forehead, 'left_cheek': pulses_leftc, 'right_cheek': pulses_rightc}\n",
    "    datadf = {'forehead': pulses_forehead, 'left_cheek': pulses_leftc, 'right_cheek': pulses_rightc}\n",
    "    df = pd.DataFrame(datadf)\n",
    "    correlation_matrix = df.corr()  \n",
    "    \n",
    "    data = {\n",
    "    'fl': round(correlation_matrix['forehead']['left_cheek'],2),\n",
    "    'fr': round(correlation_matrix['forehead']['right_cheek'],2),\n",
    "    'rl': round(correlation_matrix['right_cheek']['left_cheek'],2),\n",
    "    'facecount': 1,\n",
    "    'error':0\n",
    "    }\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c27458c-6a35-4a94-9433-b9ca3b72d7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0001.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0001.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0002.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0002.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0003.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0003.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0004.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0004.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0005.mp4\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0005.mp4\n",
      "False\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "excel_file = 'celebDF_DS.xlsx'  # Replace with the path to your Excel file\n",
    "results=[]\n",
    "# Read the existing Excel file    \n",
    "existing_df = pd.read_excel(excel_file)\n",
    "count=5\n",
    "for filepath in existing_df['filepath']:\n",
    "    print(filepath)\n",
    "    result = calculateResult(filepath)\n",
    "    results.append(result)\n",
    "    print(result)\n",
    "    if(count==0):\n",
    "        break\n",
    "    count-=1\n",
    "print(\"Done\")\n",
    "# updating Results DataSet\n",
    "# try:\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     updated_df = updated_df = pd.concat([existing_df, result_df], axis=1)\n",
    "#     save_excel_file(updated_df, excel_file)        \n",
    "#     print(\"The new columns have been added to the Excel file.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
