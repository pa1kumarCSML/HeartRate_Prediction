{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77a650c-607e-43e7-bd90-b879971eec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.signal import butter, filtfilt, lfilter\n",
    "from scipy.fft import fft, fftfreq\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20066f42-c946-4958-ba84-65c83a6285d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "low_cutoff = 0.75\n",
    "high_cutoff = 2.5\n",
    "fps=0\n",
    "fs = 2 * high_cutoff\n",
    "\n",
    "#Paths\n",
    "dlib_path = 'dlib_files/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "\n",
    "\n",
    "#pulses values\n",
    "pulses_forehead=[]\n",
    "pulses_leftc=[]\n",
    "pulses_rightc=[]\n",
    "# pulses_fullf=[]\n",
    "\n",
    "# Create a new DataFrame with new columns data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0689a4b-430b-4a4f-88e0-44b82a06b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "\n",
    "def setValues():\n",
    "    #Constants\n",
    "    low_cutoff = 0.75\n",
    "    high_cutoff = 2.5\n",
    "    fs = 2 * high_cutoff    \n",
    "    #pulses values\n",
    "    pulses_forehead=[]\n",
    "    pulses_leftc=[]\n",
    "    pulses_rightc=[]\n",
    "    # pulses_fullf=[]\n",
    "\n",
    "\n",
    "def calculate_pulse_signal(roi,pulses):\n",
    "    \n",
    "    B, G, R = cv2.split(roi)\n",
    "    \n",
    "    #Normalizing R,G,B channels\n",
    "    \n",
    "    Rn = R / np.mean(R)\n",
    "    Gn = G / np.mean(G)\n",
    "    Bn = B / np.mean(B)    \n",
    "    \n",
    "    #CHROM Signals\n",
    "    \n",
    "    Xs = 3*Rn - 2*Gn\n",
    "    Ys = 1.5*Rn + Gn - 1.5*Bn\n",
    "    \n",
    "    Rf = apply_bandpass_filter(Rn)\n",
    "    Gf = apply_bandpass_filter(Gn)\n",
    "    Bf = apply_bandpass_filter(Bn)\n",
    "    Xf = apply_bandpass_filter(Xs)\n",
    "    Yf = apply_bandpass_filter(Ys)\n",
    "\n",
    "    alpha = np.std(Xf) / np.std(Yf)\n",
    "\n",
    "    Signal = 3*(1-(alpha/2))*Rf - 2*(1 + (alpha/2))*Gf + ((3*alpha)/2)*Bf\n",
    "    \n",
    "    pulses.append(np.mean(Signal))  \n",
    "\n",
    "def apply_bandpass_filter(channel, order=5):\n",
    "    b, a = butter_bandpass(order)\n",
    "    y = filtfilt(b, a, channel, axis=0,padlen=0)\n",
    "    return y\n",
    "\n",
    "def butter_bandpass(order=5):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    lowcut_norm = low_cutoff / nyquist \n",
    "    highcut_norm = high_cutoff / nyquist\n",
    "    b, a = butter(order, [lowcut_norm, highcut_norm-0.1], btype='band')\n",
    "    return b, a\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd5d9fc-c94d-444f-bfe0-08db04b0115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "\n",
    "def calculateResult(file_path):\n",
    "    data = {\n",
    "    'fl': np.nan,\n",
    "    'fr': np.nan,\n",
    "    'rl': np.nan,\n",
    "    'facecount': np.nan,\n",
    "    'error':0\n",
    "    }\n",
    "    # Load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(dlib_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    setValues()\n",
    "    \n",
    "    # Process each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            # handle if not ret\n",
    "            data['error'] = 1\n",
    "            print(\"In ret\")\n",
    "            return data\n",
    "            break\n",
    "    \n",
    "        # Convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Detect faces in the frame\n",
    "        faces = detector(gray)\n",
    "        \n",
    "        if(len(faces) > 1):\n",
    "            data['facecount'] = len(faces)\n",
    "            return data\n",
    "            break\n",
    "    \n",
    "        # Process each detected face\n",
    "        for face in faces:\n",
    "            # Detect facial landmarks\n",
    "            landmarks = predictor(gray, face)\n",
    "            \n",
    "            # Identify forehead region based on landmarks\n",
    "            forehead_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            forehead_r1[0] = landmarks.part(21).x # Left eyebrow-x\n",
    "            forehead_r1[1] = landmarks.part(22).x  # Right eyebrow-x\n",
    "            forehead_r1_height=int((forehead_r1[1] - forehead_r1[0]))\n",
    "            forehead_r1[2] = landmarks.part(21).y - forehead_r1_height # Left eyebrow-y\n",
    "            forehead_r1[3] = landmarks.part(22).y # Right eyebrow-y\n",
    "            \n",
    "            # Identify left cheek region-1 based on landmarks\n",
    "            leftc_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            leftc_r1[0]=landmarks.part(41).x\n",
    "            leftc_r1[1]=landmarks.part(39).x\n",
    "            leftc_r1[2]=landmarks.part(28).y\n",
    "            leftc_r1[3]=landmarks.part(30).y\n",
    "    \n",
    "            # Identify right cheek region-1 based on landmarks\n",
    "            rightc_r1=[0,0,0,0] #x1,x2,y1,y2\n",
    "            \n",
    "            rightc_r1[0]=landmarks.part(42).x\n",
    "            rightc_r1[1]=landmarks.part(46).x\n",
    "            rightc_r1[2]=landmarks.part(28).y\n",
    "            rightc_r1[3]=landmarks.part(30).y\n",
    "            \n",
    "            try:\n",
    "                calculate_pulse_signal(frame[forehead_r1[2]:forehead_r1[3],forehead_r1[0]:forehead_r1[1]],pulses_forehead)\n",
    "                calculate_pulse_signal(frame[leftc_r1[2]:leftc_r1[3],leftc_r1[0]:leftc_r1[1]],pulses_leftc)\n",
    "                calculate_pulse_signal(frame[rightc_r1[2]:rightc_r1[3],rightc_r1[0]:rightc_r1[1]],pulses_rightc)   \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                data['error']=1\n",
    "                return data\n",
    "    \n",
    "        # Exit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            # handle if q pressed\n",
    "            break\n",
    "    # Release video capture\n",
    "    cap.release()\n",
    "\n",
    "    # data = {'full_face': pulses_fullf, 'forehead': pulses_forehead, 'left_cheek': pulses_leftc, 'right_cheek': pulses_rightc}\n",
    "    datadf = {'forehead': pulses_forehead, 'left_cheek': pulses_leftc, 'right_cheek': pulses_rightc}\n",
    "    df = pd.DataFrame(datadf)\n",
    "    correlation_matrix = df.corr()  \n",
    "    \n",
    "    data = {\n",
    "    'fl': round(correlation_matrix['forehead']['left_cheek'],2),\n",
    "    'fr': round(correlation_matrix['forehead']['right_cheek'],2),\n",
    "    'rl': round(correlation_matrix['right_cheek']['left_cheek'],2),\n",
    "    'facecount': 1,\n",
    "    'error':0\n",
    "    }\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c27458c-6a35-4a94-9433-b9ca3b72d7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0001.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0002.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0003.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0004.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "In ret\n",
      "C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0005.mp4\n",
      "{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}\n",
      "Done\n",
      "[{'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}, {'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}, {'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}, {'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}, {'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}, {'fl': nan, 'fr': nan, 'rl': nan, 'facecount': nan, 'error': 1}]\n"
     ]
    }
   ],
   "source": [
    "excel_file = 'celebDF_DS.xlsx'  # Replace with the path to your Excel file\n",
    "results=[]\n",
    "# Read the existing Excel file    \n",
    "existing_df = pd.read_excel(excel_file)\n",
    "count=5\n",
    "for filepath in existing_df['filepath']:\n",
    "    print('hi')\n",
    "    result = calculateResult('C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4')\n",
    "    print(filepath)\n",
    "    results.append(result)\n",
    "    print(result)\n",
    "    if(count==0):\n",
    "        break\n",
    "    count-=1\n",
    "print(\"Done\")\n",
    "print(results)\n",
    "# updating Results DataSet\n",
    "# try:\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     updated_df = updated_df = pd.concat([existing_df, result_df], axis=1)\n",
    "#     save_excel_file(updated_df, excel_file)        \n",
    "#     print(\"The new columns have been added to the Excel file.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dd9092-3ebb-449f-9d37-f42811aef88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    106\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 107\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcalculateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m, in \u001b[0;36mcalculateResult\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load face detector and facial landmark predictor\u001b[39;00m\n\u001b[0;32m     28\u001b[0m detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[1;32m---> 29\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdlib_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(file_path)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Path to dlib's shape predictor model\n",
    "dlib_path = \"dlib_files/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Dummy functions for setValues and calculate_pulse_signal\n",
    "def setValues():\n",
    "    global pulses_forehead, pulses_leftc, pulses_rightc\n",
    "    pulses_forehead, pulses_leftc, pulses_rightc = [], [], []\n",
    "\n",
    "def calculate_pulse_signal(region, pulse_list):\n",
    "    # Dummy pulse calculation (replace with actual implementation)\n",
    "    pulse_list.append(np.mean(region))\n",
    "\n",
    "def calculateResult(file_path):\n",
    "    data = {\n",
    "        'fl': np.nan,\n",
    "        'fr': np.nan,\n",
    "        'rl': np.nan,\n",
    "        'facecount': np.nan,\n",
    "        'error': 0\n",
    "    }\n",
    "\n",
    "    # Load face detector and facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(dlib_path)\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {file_path}\")\n",
    "        data['error'] = 1\n",
    "        return data\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    setValues()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to read frame\")\n",
    "            data['error'] = 1\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "        \n",
    "        if len(faces) > 1:\n",
    "            data['facecount'] = len(faces)\n",
    "            break\n",
    "    \n",
    "        for face in faces:\n",
    "            landmarks = predictor(gray, face)\n",
    "            \n",
    "            forehead_r1 = [\n",
    "                landmarks.part(21).x, landmarks.part(22).x, \n",
    "                landmarks.part(21).y - (landmarks.part(22).x - landmarks.part(21).x), \n",
    "                landmarks.part(22).y\n",
    "            ]\n",
    "            \n",
    "            leftc_r1 = [\n",
    "                landmarks.part(41).x, landmarks.part(39).x, \n",
    "                landmarks.part(28).y, landmarks.part(30).y\n",
    "            ]\n",
    "            \n",
    "            rightc_r1 = [\n",
    "                landmarks.part(42).x, landmarks.part(46).x, \n",
    "                landmarks.part(28).y, landmarks.part(30).y\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                calculate_pulse_signal(frame[forehead_r1[2]:forehead_r1[3], forehead_r1[0]:forehead_r1[1]], pulses_forehead)\n",
    "                calculate_pulse_signal(frame[leftc_r1[2]:leftc_r1[3], leftc_r1[0]:leftc_r1[1]], pulses_leftc)\n",
    "                calculate_pulse_signal(frame[rightc_r1[2]:rightc_r1[3], rightc_r1[0]:rightc_r1[1]], pulses_rightc)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                data['error'] = 1\n",
    "                return data\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if data['error'] == 1:\n",
    "        return data\n",
    "\n",
    "    datadf = {'forehead': pulses_forehead, 'left_cheek': pulses_leftc, 'right_cheek': pulses_rightc}\n",
    "    df = pd.DataFrame(datadf)\n",
    "    correlation_matrix = df.corr()\n",
    "    \n",
    "    data = {\n",
    "        'fl': round(correlation_matrix['forehead']['left_cheek'], 2),\n",
    "        'fr': round(correlation_matrix['forehead']['right_cheek'], 2),\n",
    "        'rl': round(correlation_matrix['right_cheek']['left_cheek'], 2),\n",
    "        'facecount': 1,\n",
    "        'error': 0\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "file_path = 'C:/Users/dpava/Desktop/celeb_df_v1/Celeb-real/id0_0000.mp4'\n",
    "result = calculateResult(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11793dd-6416-460c-8f7d-b52f0e19ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
